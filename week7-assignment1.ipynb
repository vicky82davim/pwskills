{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b144997-b2c3-4a8f-bada-9b49bf881f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Web scraping refers to the extraction of data from a website.\n",
    "Search engine bots crawling a site, analyzing its content and then ranking it.\n",
    "Price comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\n",
    "Market research companies using scrapers to pull data from forums and social media (e.g., for sentiment analysis)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057cd8b-f06c-4ae6-b2ac-76c4adfc9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1. HTML parsing, involves the use of JavaScript to target a linear or nested HTML page.\n",
    "2. The Document Object Model (DOM) defines the structure, style and content of an XML file. \n",
    "Scrapers typically use a DOM parser to view the structure of web pages in depth\n",
    "3. XPath is short for XML Path Language, which is a query language for XML documents. \n",
    "XML documents have tree-like structures, so scrapers can use XPath to navigate through them by selecting \n",
    "nodes according to various parameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e4132-185a-4da4-ba2f-4b86d16e56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Beautiful soup is a Python module. It is used to structure the html content\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b1644-548d-451f-8753-3968a0095a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Flask is a lightweight framework to build websites. Weâ€™ll use this to parse our collected data and display it \n",
    "as HTML in a new HTML file.\n",
    "The requests module allows us to send http requests to the website we want to scrape.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14da89e-0657-4f2d-b94e-39d06014bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "AWS Beanstalk: Elastic Beanstalk is used for deploying and scaling web applications. \n",
    "In simple terms this platform as a service (PaaS) takes your application code and deploys it while \n",
    "provisioning the supporting architecture and compute resources required for your code to run\n",
    "\n",
    "AWS Code Pipeline: AWS CodePipeline is a continuous delivery service you can use to model, \n",
    "visualize, and automate the steps required to release your software. We connect with github repository with it and \n",
    "deploy code automatically to AWS beakstalk\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
