{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433850aa-16a8-4a52-ba97-14d5db9c1db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\\napplication.\\n\\nANS:\\nMin-Max scaling is another way of data scaling, where the minimum of feature is made equal to zero and the maximum of feature equal to one. MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution.\\nx_std = (x – x.min(axis=0)) / (x.max(axis=0) – x.min(axis=0))\\n\\nx_scaled = x_std * (max – min) + min\\n•\\tmin, max = feature_range\\n•\\tx.min(axis=0) : Minimum feature value\\n•\\tx.max(axis=0):Maximum feature value\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "ANS:\n",
    "Min-Max scaling is another way of data scaling, where the minimum of feature is made equal to zero and the maximum of feature equal to one. MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution.\n",
    "x_std = (x – x.min(axis=0)) / (x.max(axis=0) – x.min(axis=0))\n",
    "\n",
    "x_scaled = x_std * (max – min) + min\n",
    "•\tmin, max = feature_range\n",
    "•\tx.min(axis=0) : Minimum feature value\n",
    "•\tx.max(axis=0):Maximum feature value\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1eb6709-417c-407d-86f3-100b34380da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.        ]\n",
      " [0.27272727 0.625     ]\n",
      " [0.         1.        ]\n",
      " [1.         0.75      ]]\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "# create data\n",
    "data = [[11, 2], [3, 7], [0, 10], [11, 8]]\n",
    " \n",
    "# scale features\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(data)\n",
    "scaled_data=model.transform(data)\n",
    " \n",
    "# print scaled features\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035a11e5-68fc-4687-9424-5a8320917777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\\nProvide an example to illustrate its application.\\n\\nANS:\\nUnit vectors are the vectors that are used to give the direction of the vector. We can easily get the unit vector of the vector by simply dividing the vector by its magnitude.\\n\\nMagnitude of Vector\\nThe strength of any vector is given by the magnitude of the vector. Any vector has both magnitude and direction and the magnitude of the vector is calculated by taking the sum of the square of individual components of the vector and then taking its square root. For any vec{A}   = ai + bj + ck the vector’s magnitude formula is,\\n\\n|vec{A}|  = √(a2 + b2 + c2)\\n\\nExample: Find the magnitude of vector vec{V}   = 2i + 3k – j\\n\\nSolution:\\n\\nGiven Vector,\\n\\nvec{V}   = 2i + 3k – j\\n\\nMagnitude of vector\\n\\n|V| = √((2)2 + (3)2 + (-1)2)\\n\\n|V| = √(14) units\\n\\nNormalization\\nRescales values to a range between 0 and 1\\nUseful when the distribution of the data is unknown or not Gaussian\\nSensitive to outliers\\nRetains the shape of the original distribution\\nMay not preserve the relationships between the data points\\nEquation: (x – min)/(max – min)\\n\\n\\nStandardization\\nCenters data around the mean and scales to a standard deviation of 1\\nUseful when the distribution of the data is Gaussian or unknown\\nLess sensitive to outliers\\nChanges the shape of the original distribution\\nPreserves the relationships between the data points\\nEquation: (x – mean)/standard deviation\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "ANS:\n",
    "Unit vectors are the vectors that are used to give the direction of the vector. We can easily get the unit vector of the vector by simply dividing the vector by its magnitude.\n",
    "\n",
    "Magnitude of Vector\n",
    "The strength of any vector is given by the magnitude of the vector. Any vector has both magnitude and direction and the magnitude of the vector is calculated by taking the sum of the square of individual components of the vector and then taking its square root. For any vec{A}   = ai + bj + ck the vector’s magnitude formula is,\n",
    "\n",
    "|vec{A}|  = √(a2 + b2 + c2)\n",
    "\n",
    "Example: Find the magnitude of vector vec{V}   = 2i + 3k – j\n",
    "\n",
    "Solution:\n",
    "\n",
    "Given Vector,\n",
    "\n",
    "vec{V}   = 2i + 3k – j\n",
    "\n",
    "Magnitude of vector\n",
    "\n",
    "|V| = √((2)2 + (3)2 + (-1)2)\n",
    "\n",
    "|V| = √(14) units\n",
    "\n",
    "Normalization\n",
    "Rescales values to a range between 0 and 1\n",
    "Useful when the distribution of the data is unknown or not Gaussian\n",
    "Sensitive to outliers\n",
    "Retains the shape of the original distribution\n",
    "May not preserve the relationships between the data points\n",
    "Equation: (x – min)/(max – min)\n",
    "\n",
    "\n",
    "Standardization\n",
    "Centers data around the mean and scales to a standard deviation of 1\n",
    "Useful when the distribution of the data is Gaussian or unknown\n",
    "Less sensitive to outliers\n",
    "Changes the shape of the original distribution\n",
    "Preserves the relationships between the data points\n",
    "Equation: (x – mean)/standard deviation\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc782264-d83f-4eed-8aa9-26e311deca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\\nexample to illustrate its application.\\n\\nANS:\\nThe Principal Component Analysis is a popular unsupervised learning technique for reducing the dimensionality of large data sets. It increases interpretability yet, at the same time, it minimizes information loss. It helps to find the most significant features in a dataset and makes the data easy for plotting in 2D and 3D. PCA helps in finding a sequence of linear combinations of variables.\\n\\nPrincipal Component\\nThe Principal Components are a straight line that captures most of the variance of the data. They have a direction and magnitude\\n\\nDimensionality\\nThe term \"dimensionality\" describes the quantity of features or variables used in the research. It can be difficult to visualize and interpret the relationships between variables when dealing with high-dimensional data, such as datasets with numerous variables. While reducing the number of variables in the dataset, dimensionality reduction methods like PCA are used to preserve the most crucial data. The original variables are converted into a new set of variables called principal components, which are linear combinations of the original variables, by PCA in order to accomplish this. The dataset\\'s reduced dimensionality depends on how many principal components are used in the study. The objective of PCA is to select fewer principal components that account for the data\\'s most important variation.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "ANS:\n",
    "The Principal Component Analysis is a popular unsupervised learning technique for reducing the dimensionality of large data sets. It increases interpretability yet, at the same time, it minimizes information loss. It helps to find the most significant features in a dataset and makes the data easy for plotting in 2D and 3D. PCA helps in finding a sequence of linear combinations of variables.\n",
    "\n",
    "Principal Component\n",
    "The Principal Components are a straight line that captures most of the variance of the data. They have a direction and magnitude\n",
    "\n",
    "Dimensionality\n",
    "The term \"dimensionality\" describes the quantity of features or variables used in the research. It can be difficult to visualize and interpret the relationships between variables when dealing with high-dimensional data, such as datasets with numerous variables. While reducing the number of variables in the dataset, dimensionality reduction methods like PCA are used to preserve the most crucial data. The original variables are converted into a new set of variables called principal components, which are linear combinations of the original variables, by PCA in order to accomplish this. The dataset's reduced dimensionality depends on how many principal components are used in the study. The objective of PCA is to select fewer principal components that account for the data's most important variation.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e81d3e5-94e2-4594-b9d7-872692cc88e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\\nExtraction? Provide an example to illustrate this concept.\\n\\nANS:\\nIn real-world machine learning problems, there are often too many factors (features) on the basis of which the final prediction is done. The higher the number of features, the harder it gets to visualize the training set and then work on it.\\nDimensionality reduction is the process of reducing the number of random features under consideration, by obtaining a set of principal or important features.\\n\\nDimensionality reduction can be done in 2 ways:\\n\\na. Feature Selection: By only keeping the most relevant variables from the original dataset\\n\\ni. Correlation\\n\\nii. Forward Selection\\n\\niii. Backward Elimination\\n\\niv. Select K Best\\n\\nv. Missing value Ratio\\n\\nb. Feature Extraction: By finding a smaller set of new variables, each being a combination of the input variables, containing basically the same information as the input variables.\\n\\ni.\\tPCA(Principal Component Analysis):\\nPCA is a method of obtaining important variables (in form of components) from a large set of variables available in a data set. It tends to find the direction of maximum variation (spread) in data. PCA is more useful when dealing with 3 or higher-dimensional data.\\n\\nPCA can be used for anomaly detection and outlier detection because they will not be part of the data as it would be considered noise by PCA\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "ANS:\n",
    "In real-world machine learning problems, there are often too many factors (features) on the basis of which the final prediction is done. The higher the number of features, the harder it gets to visualize the training set and then work on it.\n",
    "Dimensionality reduction is the process of reducing the number of random features under consideration, by obtaining a set of principal or important features.\n",
    "\n",
    "Dimensionality reduction can be done in 2 ways:\n",
    "\n",
    "a. Feature Selection: By only keeping the most relevant variables from the original dataset\n",
    "\n",
    "i. Correlation\n",
    "\n",
    "ii. Forward Selection\n",
    "\n",
    "iii. Backward Elimination\n",
    "\n",
    "iv. Select K Best\n",
    "\n",
    "v. Missing value Ratio\n",
    "\n",
    "b. Feature Extraction: By finding a smaller set of new variables, each being a combination of the input variables, containing basically the same information as the input variables.\n",
    "\n",
    "i.\tPCA(Principal Component Analysis):\n",
    "PCA is a method of obtaining important variables (in form of components) from a large set of variables available in a data set. It tends to find the direction of maximum variation (spread) in data. PCA is more useful when dealing with 3 or higher-dimensional data.\n",
    "\n",
    "PCA can be used for anomaly detection and outlier detection because they will not be part of the data as it would be considered noise by PCA\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da795b63-105c-49f6-908a-a4f888a22502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQ5. You are working on a project to build a recommendation system for a food delivery service. The dataset\\ncontains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\\npreprocess the data.\\n\\nANS:\\nImport pandas as pd\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\n# initialize list of lists \\ndata = [[1000, 5, 2], [500, 3, 1], [760, 4, 3], [430, 5, 2], [790, 2, 2]]\\n# Create the pandas DataFrame \\ndf = pd.DataFrame(data, columns= [ ‘price’, 'rating', ‘deliverytime’])\\n# define min max scaler\\nscaler = MinMaxScaler()\\n# transform data\\nscaled = scaler.fit_transform(df[[ ‘price’, 'rating', ‘deliverytime’]])\\nprint(scaled)\\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "ANS:\n",
    "Import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# initialize list of lists \n",
    "data = [[1000, 5, 2], [500, 3, 1], [760, 4, 3], [430, 5, 2], [790, 2, 2]]\n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns= [ ‘price’, 'rating', ‘deliverytime’])\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(df[[ ‘price’, 'rating', ‘deliverytime’]])\n",
    "print(scaled)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d9774f-e2f8-41e2-9893-99688d5bfecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ6. You are working on a project to build a model to predict stock prices. The dataset contains many\\nfeatures, such as company financial data and market trends. Explain how you would use PCA to reduce the\\ndimensionality of the dataset.\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8073d1-bbd8-4832-a938-e23d2e3d7a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # to load the dataframe\n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "import seaborn as sns  # to plot the heat maps\n",
    "\n",
    "# initialize list of lists \n",
    "data = [[1000, 5], [500, 3], [760, 4], [430, 5], [790, 2]]\n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns= [ 'financial_data', 'market_trend'])\n",
    "\n",
    "#Standardize the features\n",
    "#Create an object of StandardScaler which is present in sklearn.preprocessing\n",
    "scalar = StandardScaler() \n",
    "scaled_data = pd.DataFrame(scalar.fit_transform(df)) #scaling the data\n",
    "scaled_data\n",
    "\n",
    "\n",
    "#Check the Co-relation between features without PCA\n",
    "sns.heatmap(scaled_data.corr())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a177facf-cb6a-4ee7-b4ab-50fc63299b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Applying PCA\n",
    "#Taking no. of Principal Components as 2\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(scaled_data)\n",
    "data_pca = pca.transform(scaled_data)\n",
    "data_pca = pd.DataFrame(data_pca,columns=['PC1','PC2'])\n",
    "data_pca.head()\n",
    "\n",
    "#Checking Co-relation between features after PCA\n",
    "sns.heatmap(data_pca.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e3a09b-6192-405a-b094-44c48977f67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\\nvalues to a range of -1 to 1.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5d985d7-ff99-403c-8c99-ed8a69cf24fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.21052632]\n",
      " [0.47368421]\n",
      " [0.73684211]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# initialize list of lists \n",
    "data = [1, 5, 10, 15, 20]\n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns= [ 'numb'])\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(df[[ 'numb']])\n",
    "print(scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5612e0ec-ffb5-4e7d-a49a-928f506a91b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\\nFeature Extraction using PCA. How many principal components would you choose to retain, and why?\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "333de4f9-b8e3-4b8e-a4f6-61932a875d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "[[-0.26413527  0.51425948 -1.16915571]\n",
      " [ 0.61631563  1.15708382 -0.76249285]\n",
      " [ 1.14458618 -1.54277843  1.27082142]\n",
      " [-1.49676654 -0.12856487  0.66082714]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# initialize list of lists \n",
    "data = [[144, 60, 20,'M', 120], [154, 65, 22,'M', 120], [160, 44, 32,'F', 118], [130, 55, 29,'F', 110]]\n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns= [ 'height', 'weight', 'age','gender','bp'])\n",
    "\n",
    "## StandardScaler is used to remove the outliners and scale the data by making the mean of the data 0 and standard deviation as 1\n",
    "std_slc = StandardScaler()\n",
    "X_std = std_slc.fit_transform(df[['height', 'weight', 'age']])\n",
    "\n",
    "print(X_std.shape)\n",
    "print(X_std)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58fbe75e-426c-4ad2-9c9d-4a7cf3fe6bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[-1.21135098 -0.09600013]\n",
      " [-1.17431883 -0.87848247]\n",
      " [ 2.20872684 -0.64984088]\n",
      " [ 0.17694298  1.62432347]]\n"
     ]
    }
   ],
   "source": [
    "## We are also using Principal Component Analysis(PCA) which will reduce the dimension of features by creating new features which have most of the varience of the original data. We have passed the parameter n_components as 4 which is the number of feature in final dataset.\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_std_pca = pca.fit_transform(X_std)\n",
    "print(X_std_pca.shape)\n",
    "print(X_std_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412cea3-1c73-4367-a02e-e3a1ab792901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
